{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57d133c4-59b5-4ec2-bf99-d4c168b27685",
   "metadata": {},
   "source": [
    "## This notebook is intended to train a Decision tree classifier model using the different data generated for different classification scenarios. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ccd0985-cbd2-4b50-bf61-c2c913c9bd04",
   "metadata": {},
   "source": [
    "### Importing the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6471af5-9b3a-4415-a396-dd4e2b3f630f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import IPython\n",
    "import IPython.display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e703f914-5986-40ce-b96f-e19c0f51e2c5",
   "metadata": {},
   "source": [
    "#### Timing the training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba2f9fd-be37-47de-a93d-7ad5665904cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78820b0d-4a6a-4616-9496-c4f3d7da061d",
   "metadata": {},
   "source": [
    "#### Filenames to be used for storing models, training process and the input files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0fef2d5-e529-4853-bc3b-b82571cf90cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_str=\"RWs_H_g_2_tadv_5min_rw_0.2\"\n",
    "dt_save_name= os.getcwd() + \"/model_saves_dt\" + \"/\" +  \"/best_model_\" + file_str + \".pkl\"\n",
    "metrics_save_name = os.getcwd() + \"/metric_saves_dt\" + \"/\" + file_str + \".txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f902808-6f49-4664-96ff-92bdbca6600d",
   "metadata": {},
   "source": [
    "#### Creating the train and test data for training the LSTM model.\n",
    "**The training data for different scenarios can be accessed here.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4fc78f4-1fd7-4b4a-b625-dc7b02e1b1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ata=np.load(file_str+\".npz\")\n",
    "\n",
    "for vars in data:\n",
    "    print(vars)\n",
    "\n",
    "wave_data_train=data[\"wave_data_train\"]\n",
    "wave_data_test=data[\"wave_data_test\"]\n",
    "label_train=data[\"label_train\"]\n",
    "label_test=data[\"label_test\"]\n",
    "\n",
    "print(wave_data_train.shape)\n",
    "print(wave_data_test.shape)\n",
    "\n",
    "x_train = wave_data_train.reshape((wave_data_train.shape[0], wave_data_train.shape[1] * wave_data_train.shape[2]))\n",
    "x_test = wave_data_test.reshape((wave_data_test.shape[0], wave_data_test.shape[1] * wave_data_test.shape[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d20ef7-ace0-4a18-b92c-76e504801f98",
   "metadata": {},
   "source": [
    "**DT classification model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d309e5-edf0-44ba-9d65-3edfa4c100ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(random_state = 0)\n",
    "clf.fit(x_train, label_train)\n",
    "\n",
    "with open(dt_save_name,'wb') as f:\n",
    "    pickle.dump(clf,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8bc8aa-3c47-4e9a-96d5-fd62879073e7",
   "metadata": {},
   "source": [
    "#### Using the trained DT classifier for predicting on the test set. Confusion matrix is also created for depicting the prediction results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9679798-3cd0-4369-bdd1-bd80944dea22",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(dt_save_name,'rb') as f:\n",
    "    clf = pickle.load(f)\n",
    "    \n",
    "label_pred = clf.predict(x_test)\n",
    "\n",
    "confusion_matrix = metrics.confusion_matrix(label_test, label_pred)\n",
    "print('Confusion matrix')\n",
    "print(confusion_matrix)\n",
    "print('---------------')\n",
    "print('Precision:', metrics.precision_score(label_test, label_pred))\n",
    "print('Recall:', metrics.recall_score(label_test, label_pred))\n",
    "print('F1 Score:', metrics.f1_score(label_test, label_pred))\n",
    "\n",
    "lines = ['Confusion matrix\\n', f\"{confusion_matrix}\\n\", \"---------------\\n\",          \n",
    "         f\" 'Precision:', {metrics.precision_score(label_test, label_pred)}\",       \n",
    "f\" 'Recall:', {metrics.recall_score(label_test, label_pred)}\",        \n",
    "f\" 'F1 Score:', {metrics.f1_score(label_test, label_pred)}\"]\n",
    "with open(metrics_save_name, \"w\") as f:\n",
    "    f.writelines(lines)\n",
    "    \n",
    "group_names = ['Correctly predicted','Incorrectly predicted', 'Incorrectly predicted','Correctly predicted']\n",
    "group_counts = [\"{0:0.0f}\".format(value) for value in\n",
    "                confusion_matrix.flatten()]\n",
    "group_percentages = [\"{0:.2%}\".format(value) for value in\n",
    "                        confusion_matrix.flatten()/np.sum(confusion_matrix)]\n",
    "labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in\n",
    "            zip(group_names,group_counts,group_percentages)]\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "yaxislabels = ['Rogue waves absent','Rogue waves present']\n",
    "xaxislabels = ['Predicted as absent','Predicted as present']\n",
    "plt.figure(figsize=[6,6])\n",
    "s = sns.heatmap(confusion_matrix, annot=labels, yticklabels=yaxislabels, xticklabels=xaxislabels, fmt='', cmap='Blues')\n",
    "s.set_xlabel(\"Predicted label\", fontsize = 10)\n",
    "s.set_ylabel(\"True label\", fontsize=10)\n",
    "filename=os.getcwd()+'/confusion_matrices_dt'+'/'+file_str+'.jpg'\n",
    "plt.savefig(filename,dpi=199)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26479bc-c847-45e4-a0b7-0d3143056f15",
   "metadata": {},
   "source": [
    "#### Timing the process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43d8b52-eb74-4c3f-b7f5-9dc426331e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Elapsed time is {elapsed_time} seconds.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
