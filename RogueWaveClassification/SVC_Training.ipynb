{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "030bccf0-d4b8-4a81-9b7e-c2ead94a8d43",
   "metadata": {},
   "source": [
    "## This notebook is intended to train a support vector machine model using the different data generated for different classification scenarios. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e7d71c-209b-4300-ad7b-f385413fd4af",
   "metadata": {},
   "source": [
    "#### Importing the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627e7e4a-4ef2-4518-b9fb-6f955c9d5264",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import IPython\n",
    "import IPython.display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2610e9a2-d018-44bc-8d47-58c110687b1a",
   "metadata": {},
   "source": [
    "#### Timing the training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77bb9504-0b1b-42ce-82e2-809b742fbdbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "698d67aa-7694-494e-9c59-d8abec0082a8",
   "metadata": {},
   "source": [
    "#### Filenames to be used for storing models, training process and the input files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c4b155-1f5e-4fff-8ec4-1610ad64ed33",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_str=\"RWs_H_g_2_tadv_10min_deep_buoys_rw_0.5\"\n",
    "file_str_test = \"RWs_H_g_2_tadv_10min_deep_buoys_test_rw_0.5\"\n",
    "\n",
    "svm_save_name= os.getcwd() + \"/model_saves_svm\" + \"/\" +  \"/best_model_\" + file_str + \".pkl\"\n",
    "metrics_save_name = os.getcwd() + \"/metric_saves_svm\" + \"/\" + file_str + \".txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38fd2f37-6fef-47aa-a51a-54617166c195",
   "metadata": {},
   "source": [
    "#### Creating the train and test data for training the SVM model.\n",
    "**The training data for different scenarios can be accessed here.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071ab7c8-ed2c-4eb7-b57c-2c86b82dbe8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=np.load(file_str+\".npz\")\n",
    "data_test = np.load(file_str_test+\".npz\")\n",
    "\n",
    "\n",
    "for vars in data:\n",
    "    print(vars)\n",
    "\n",
    "wave_data_train=data[\"wave_data_train\"]\n",
    "wave_data_test=data_test[\"wave_data_test\"]\n",
    "label_train=data[\"label_train\"]\n",
    "label_test=data_test[\"label_test\"]\n",
    "\n",
    "print(wave_data_train.shape)\n",
    "print(wave_data_test.shape)\n",
    "\n",
    "x_train = wave_data_train.reshape((wave_data_train.shape[0], wave_data_train.shape[1] * wave_data_train.shape[2]))\n",
    "x_test = wave_data_test.reshape((wave_data_test.shape[0], wave_data_test.shape[1] * wave_data_test.shape[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb9d0f0-ba4b-4e25-a012-a472b5d56fbd",
   "metadata": {},
   "source": [
    "#### SVM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58313a61-4365-4f34-b26d-5fa259c1950c",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC(C=1.0,kernel='rbf', random_state = 0, verbose=True)\n",
    "clf.fit(x_train, label_train)\n",
    "\n",
    "with open(svm_save_name,'wb') as f:\n",
    "    pickle.dump(clf,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "235d6aba-fd67-46e4-836d-1c62d1255b12",
   "metadata": {},
   "source": [
    "#### Using the trained SVM classifier for predicting on the test set. Confusion matrix is also created for depicting the prediction results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956c1923-2fae-4a78-8919-f7c2311cd3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(dt_save_name,'rb') as f:\n",
    "    clf = pickle.load(f)\n",
    "\n",
    "label_pred = clf.predict(x_test)\n",
    "\n",
    "confusion_matrix = metrics.confusion_matrix(label_test, label_pred)\n",
    "print('Confusion matrix')\n",
    "print(confusion_matrix)\n",
    "print('---------------')\n",
    "print('Precision:', metrics.precision_score(label_test, label_pred))\n",
    "print('Recall:', metrics.recall_score(label_test, label_pred))\n",
    "print('F1 Score:', metrics.f1_score(label_test, label_pred))\n",
    "\n",
    "lines = ['Confusion matrix\\n', f\"{confusion_matrix}\\n\", \"---------------\\n\", f\" 'Precision:', {metrics.precision_score(label_test, label_pred)}\",         f\" 'Recall:', {metrics.recall_score(label_test, label_pred)}\",         f\" 'F1 Score:', {metrics.f1_score(label_test, label_pred)}\"]\n",
    "with open(metrics_save_name, \"w\") as f:\n",
    "    f.writelines(lines)\n",
    "    \n",
    "group_names = ['Correctly predicted','Incorrectly predicted','Incorrectly predicted','Correctly predicted']\n",
    "group_counts = [\"{0:0.0f}\".format(value) for value in\n",
    "                confusion_matrix.flatten()]\n",
    "group_percentages = [\"{0:.2%}\".format(value) for value in\n",
    "                        confusion_matrix.flatten()/np.sum(confusion_matrix)]\n",
    "labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in\n",
    "            zip(group_names,group_counts,group_percentages)]\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "yaxislabels = ['Rogue waves absent','Rogue waves present']\n",
    "xaxislabels = ['Predicted as absent','Predicted as present']\n",
    "plt.figure(figsize=[6,6])\n",
    "s = sns.heatmap(confusion_matrix, annot=labels, yticklabels=yaxislabels, xticklabels=xaxislabels, fmt='', cmap='Blues')\n",
    "s.set_xlabel(\"Predicted label\", fontsize = 10)\n",
    "s.set_ylabel(\"True label\", fontsize=10)\n",
    "filename=os.getcwd()+'/confusion_matrices_dt'+'/'+file_str+'.jpg'\n",
    "plt.savefig(filename,dpi=199)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07de89d5-2881-4307-a6ca-27c981485bba",
   "metadata": {},
   "source": [
    "#### Timing the process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad6adb1-fe06-4bef-a4e5-b3c3d15339ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Elapsed time is {elapsed_time} seconds.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
